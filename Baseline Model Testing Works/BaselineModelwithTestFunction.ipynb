{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE CRNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will contain the model and it will divided into 4 modules chiefly.\n",
    "\n",
    "### 1)Utility Functions\n",
    "\n",
    "### 2)Dataset\n",
    "\n",
    "### 3)Model (The skeleton is always fun to build. How the data pours through the hourglass.....)\n",
    "\n",
    "### 4)(Training) (FUNNNNN Part, But always pray to GOD, it goes right.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Also remember to install the dependencies or nothing will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Hard to write and not the fun part)\n",
    "### (Required for data encoding and decoding)\n",
    "### (Also some necessary metric helper functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports for utility functions\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#####################METRICS Functions############################################################\n",
    "\n",
    "\n",
    "\n",
    "#####################Function to calculate Average Edit Distance (NOT word error rate)############\n",
    "\n",
    "\n",
    "#required for word error rate (WER)\n",
    "#pip install python-Levenshtein\n",
    "#preferred , pip install python-Levenshtein==0.12.0\n",
    "import Levenshtein as Lev\n",
    "\n",
    "#WER functions\n",
    "def compute_wer(predictions, labels):\n",
    "    total_dist = 0\n",
    "    \n",
    "    #Check if prediction and original label are same\n",
    "    assert len(predictions) == len(labels)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        total_dist += Lev.distance(predictions[i], labels[i])\n",
    "\n",
    "    word_error_rate = ( total_dist/len(predictions) )\n",
    "\n",
    "    return word_error_rate\n",
    "\n",
    "####################Metric which counts the number of words that absolutely match####################\n",
    "\n",
    "#Absolute matching function\n",
    "def absolute_word_match(predictions, labels):\n",
    "    count_correct = 0\n",
    "    for x, y in zip(predictions, labels):\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "        if(x==y):\n",
    "            count_correct += 1\n",
    "    print(\"Absolute word match count is {}\".format(count_correct) )\n",
    "\n",
    "    return count_correct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################Preprocessing functions#####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(data_dir):\n",
    "    grapheme_dict = {}\n",
    "    labels = []\n",
    "    words = []\n",
    "    lengths = []\n",
    "    count = 2\n",
    "    filenames = os.listdir(data_dir)\n",
    "    filenames = sorted(filenames, key=lambda x: int(x.split('_')[0]))\n",
    "\n",
    "    grapheme_dict['<eow>'] = 1\n",
    "\n",
    "    for i, name in enumerate(filenames):\n",
    "        curr_word = name.split('_')[1][:-4]\n",
    "        # print(curr_word)\n",
    "        curr_label = []\n",
    "        words.append(curr_word)\n",
    "        graphemes = extract_graphemes(curr_word)\n",
    "        if 'স্ক্র্' in graphemes:\n",
    "            print(curr_word)\n",
    "            print(graphemes)\n",
    "        for grapheme in graphemes:\n",
    "            if grapheme not in grapheme_dict:\n",
    "                grapheme_dict[grapheme] = count\n",
    "                curr_label.append(count)\n",
    "                count += 1\n",
    "            else:\n",
    "                curr_label.append(grapheme_dict[grapheme])\n",
    "        lengths.append(len(curr_label))\n",
    "        labels.append(curr_label)\n",
    "    \n",
    "\n",
    "    inv_grapheme_dict = {v: k for k, v in grapheme_dict.items()}\n",
    "    #print(grapheme_dict)\n",
    "    return grapheme_dict, inv_grapheme_dict, words, labels, lengths\n",
    "\n",
    "\n",
    "#Backup, Imranul's 1st\n",
    "###################################Decodes list of characters from it's numeric mapping################\n",
    "\n",
    "\n",
    "def decode_prediction(preds, inv_grapheme_dict, raw = False):\n",
    "    grapheme_list = []\n",
    "    pred_list = []\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] != 0 and preds[i] != 1 and (not (i > 0 and preds[i - 1] == preds[i])):\n",
    "            grapheme_list.append(inv_grapheme_dict.get(preds[i]))\n",
    "            pred_list.append(preds[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    #print(pred_list,\"+\",grapheme_list)\n",
    "    return pred_list, ''.join(grapheme_list)\n",
    "\n",
    "\n",
    "\n",
    "####################################Extracts graphemes(letters) from dataset and throws away useless ones####\n",
    "###################You can try to understand it but will require Bangla Grammer skills and good logic ######\n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "def extract_graphemes(word):\n",
    "    support_chars = ['্', 'ং', 'ঃ', 'ঁ', 'ি', 'ু', 'ূ', 'ৃ', 'ে', 'ো', 'ৌ' ,'ী', 'া', 'ে', 'ৈ']\n",
    "    ref_chars = [ '্য', '্র', 'র্', 'য', 'র']\n",
    "    unicode_garbage = ['\\x02', '\\x03', '\\x06', '\\x08', '\\x10', '\\x12', '&', '¡',\n",
    "                        '¤', '¥', '¦', '©', '¬', '\\xad', '®', '¯', 'Ä', 'Í', 'ä', 'æ', 'è', 'ø', 'ÿ',\n",
    "                        'œ', 'š', 'Ÿ', 'ƒ', 'β', '॥', '\\u09e4', '\\u200b', '\\u200d', '\\u200f', '\\uf020',\n",
    "                        '\\uf02d', '�', '\\u200b', '\\u200c', '\\u09e5']\n",
    "    \n",
    "    chars = []\n",
    "    i = 0\n",
    "    prev_ref = False\n",
    "\n",
    "    while(i < len(word)):\n",
    "        if word[i] != support_chars[0] and word[i] not in unicode_garbage:\n",
    "            if i+1 < len(word):\n",
    "                if word[i+1] != support_chars[0]:\n",
    "                    if word[i+1] == ref_chars[-1] and i+2 < len(word):\n",
    "                        if word[i+2] == support_chars[0]:\n",
    "                            chars.append(word[i])\n",
    "                            chars.append(ref_chars[2])\n",
    "                            i += 2\n",
    "                            prev_ref = True\n",
    "                        else:\n",
    "                            chars.append(word[i])\n",
    "                            i += 1\n",
    "                    else:\n",
    "                        chars.append(word[i])\n",
    "                        i += 1\n",
    "                elif word[i+1] == support_chars[0] and word[i] not in support_chars[0:]:\n",
    "                    \n",
    "                    previous = False\n",
    "                    isSupport = True\n",
    "                    idx = i+1\n",
    "                    if idx<len(word):\n",
    "                        while(isSupport):\n",
    "                            if idx<len(word):\n",
    "                                #print(word[i], word[idx], i, idx)\n",
    "                                if (word[idx] == support_chars[0] or word[idx] == ref_chars[4]) and idx+1 < len(word):\n",
    "                                    if word[idx] == support_chars[0] and word[idx-1] == ref_chars[-1]:\n",
    "                                        if not previous:\n",
    "                                            if i != idx:\n",
    "                                                chars.append(word[i:(idx-1)])\n",
    "                                            chars.append(ref_chars[2])\n",
    "                                            idx += 1\n",
    "                                            i = idx\n",
    "                                            continue\n",
    "                                    if word[idx] == ref_chars[-1]:\n",
    "\n",
    "                                        if word[idx+1] != support_chars[0]:\n",
    "                                            chars.append(ref_chars[-1])\n",
    "                                        idx += 1\n",
    "                                        i = idx\n",
    "                                        continue\n",
    "                                    if word[idx+1] == ref_chars[3]:\n",
    "                                        if i != idx:\n",
    "                                            chars.append(word[i:idx])\n",
    "                                        chars.append(ref_chars[0])\n",
    "                                        idx += 2\n",
    "                                        i = idx\n",
    "                                        # print(i)\n",
    "                                        # print(idx)\n",
    "                                        continue\n",
    "                                    if word[idx+1] == ref_chars[4]:\n",
    "                                        # print(chars)\n",
    "                                        if i != idx:\n",
    "                                            chars.append(word[i:idx])\n",
    "                                        chars.append(ref_chars[1])\n",
    "                                        idx += 2\n",
    "                                        i = idx\n",
    "                                        previous = True\n",
    "                                        continue\n",
    "                                    if word[idx+1] == '\\u200c':\n",
    "                                        if i != idx:\n",
    "                                            chars.append(word[i:idx])\n",
    "                                        i = idx+2\n",
    "                                        isSupport = False\n",
    "\n",
    "                                    idx += 2\n",
    "                                else:\n",
    "                                    isSupport= False\n",
    "                            else:\n",
    "                                isSupport = False\n",
    "                    if i != idx:\n",
    "                        chars.append(word[i:idx])\n",
    "                    i = idx\n",
    "                else:\n",
    "                    if word[i] in support_chars[0:]:\n",
    "                        chars.append(word[i])\n",
    "                    i += 2\n",
    "            else:\n",
    "                chars.append(word[i])\n",
    "                i += 1\n",
    "        else:\n",
    "            if word[i]== support_chars[0]:\n",
    "                if prev_ref:\n",
    "                    prev_ref = False\n",
    "                    i += 1\n",
    "                    continue\n",
    "                chars.append(word[i])\n",
    "                i+=1\n",
    "                continue\n",
    "            else:\n",
    "                i+=1\n",
    "                continue\n",
    "        \n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that will take your dataset and wrangle it into a numeric version\n",
    "### Your computer can understand\n",
    "### Also provided is a helper function that will pad your encoded version of\n",
    "### dataset. Also get all necessary labels. Required for variable length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########OCR Dataset Class###################################################\n",
    "#########Helper functions to convert your images#############################\n",
    "#########to the desired format###############################################\n",
    "\n",
    "class  OCRDataset(data.Dataset):\n",
    "    def __init__(self, img_dir):\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        # self.text_dir = text_dir\n",
    "        self.inp_h = 32\n",
    "        self.inp_w = 128\n",
    "        self.mean = np.array(0.588, dtype=np.float32)\n",
    "        self.std = np.array(0.193, dtype=np.float32)\n",
    "        self.images = sorted(os.listdir(img_dir), key=lambda x: int(x.split('_')[0]))\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        #print(img_name)\n",
    "        \n",
    "        from skimage import io\n",
    "\n",
    "        img = io.imread(os.path.join(self.img_dir, img_name))\n",
    "        \n",
    "        #img = cv2.imread(os.path.join(self.img_dir, img_name))\n",
    "        #print(img)\n",
    "        \n",
    "        #convert to greyscale\n",
    "        \n",
    "        ##############################################Data Augmentation ####################################################\n",
    "        ####################################################################################################################\n",
    "        ####################################################################################################################\n",
    "        #def sp_noise(image,prob):\n",
    "        #    output = np.zeros(image.shape,np.uint8)\n",
    "        #    thres = 1 - prob \n",
    "        #    for i in range(image.shape[0]):\n",
    "        #        for j in range(image.shape[1]):\n",
    "        #            rdn = random.random()\n",
    "        #            if rdn < prob:\n",
    "        #                output[i][j] = 0\n",
    "        #            elif rdn > thres:\n",
    "        #                output[i][j] = 255\n",
    "        #            else:\n",
    "        #                output[i][j] = image[i][j]\n",
    "        #    return output\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        \n",
    "        #i=random.randint(0,100)\n",
    "        #print(\"random value is \",i)\n",
    "        #if(i%3==0 and i%4!=0):\n",
    "        #    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        #if(i%12==0):\n",
    "        #    img = sp_noise(img,0.02)\n",
    "            #print(\"noise added\")\n",
    "        #if(i%4==0):\n",
    "        #    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        \n",
    "        ####################################################################################################################\n",
    "        ####################################################################################################################\n",
    "\n",
    "        img_h, img_w = img.shape\n",
    "        \n",
    "        #Resize to input size for network (32,128,1)\n",
    "        img = cv2.resize(img, (0,0), fx=self.inp_w / img_w, fy=self.inp_h / img_h, interpolation=cv2.INTER_CUBIC)\n",
    "        img = np.reshape(img, (self.inp_h, self.inp_w, 1))\n",
    "\n",
    "        #Normalize by mean and standard deviation\n",
    "        img = img.astype(np.float32)\n",
    "        img = (img/255. - self.mean) / self.std\n",
    "        \n",
    "        #Reshape to tensor format supported by Pytorch (C, H, W)\n",
    "        img = img.transpose([2, 0, 1])\n",
    "        \n",
    "        return img, img_name, idx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############Helper function to pad your label lists######################################\n",
    "############Get all necessary labels from your datasets#################################\n",
    "\n",
    "def get_padded_labels(idxs, grapheme_dict, inv_grapheme_dict, words, labels, lengths):\n",
    "    batch_labels = []\n",
    "    batch_lengths = []\n",
    "    batch_words = []\n",
    "    maxlen = 0\n",
    "    #print(\"idxs\", idxs)\n",
    "    for idx in idxs:\n",
    "        batch_labels.append(labels[idx])\n",
    "        batch_words.append(words[idx])\n",
    "        #print(\"word :\",words[idx])\n",
    "        batch_lengths.append(len(labels[idx]))\n",
    "        maxlen = max(len(labels[idx]), maxlen)\n",
    "    \n",
    "    #changed [1]*(maxlen-len(batch_labels[i])) to [0]*(maxlen-len(batch_labels[i]))\n",
    "    #Alls good\n",
    "    for i in range(len(batch_labels)):\n",
    "        batch_labels[i] = batch_labels[i] + [1]*(maxlen-len(batch_labels[i]))\n",
    "\n",
    "    return batch_words, batch_labels, batch_lengths, inv_grapheme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### As said earlier the model is a collection of layers,\n",
    " \n",
    " ### A Convolutional network without it's fully connected layer\n",
    " ### What it does is extract necessary features from the image\n",
    " ### like which parts are important and such\n",
    " \n",
    " ### After we have the necessary features in rectangular form\n",
    " ### as word images are in rectangular form.\n",
    " ### we send it to a Bi-LSTM (Specialized complicated RNN)\n",
    " ### to read the image left to right and right to left \n",
    " ### and model the sequence\n",
    " \n",
    " ### The sequence predicted normally contains a lot of \n",
    " ### redundancy and repeations. The reason which\n",
    " ### we use a CTC loss to predict a variable length\n",
    " ### prediction with control of repeations.\n",
    " \n",
    " ### Remember, this is a baseline solution though.\n",
    " ### There are many better methodologies than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Necessary Imports\n",
    "import math\n",
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#######################Some module that predicts sequences from the compacted feature rich version of ########\n",
    "#######################image################################################################################\n",
    "\n",
    "\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    # Inputs hidden units Out\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)  ##marked\n",
    "        # print(output.shape)\n",
    "        return output\n",
    "\n",
    "\n",
    "#######################Forward part is the real architecture. ################################\n",
    "#######################The functions before that are used to #################################\n",
    "#######################declare the feature extracting CNN    #################################\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "        \n",
    "        \n",
    "        #########################Convolutional Backbone Declaration############################\n",
    "        \n",
    "        \n",
    "        ###kernel value for every layer\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        \n",
    "        ###padding value for every layer\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        \n",
    "        ###stride value for every layer\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        \n",
    "        ###channel value for every layer\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        ##Sequential is good way to list layers one after another.\n",
    "        ##To actually understand the syntax of Pytorch. we would\n",
    "        ## suggest learning two things: \n",
    "        \n",
    "        ## Syntax of Python classes and objects\n",
    "        ## https://www.youtube.com/watch?v=wfcWRAxRVBA&list=PLBZBJbE_rGRWeh5mIBhD-hhDwSEDxogDg&index=9\n",
    "        \n",
    "        ## For Pytorch, there's the official documents\n",
    "        ## But this medium article is enough to be honest\n",
    "        ## https://towardsdatascience.com/pytorch-how-and-when-to-use-module-sequential-modulelist-and-moduledict-7a54597b5f17\n",
    "        \n",
    "        \n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        convRelu(0)\n",
    "        \n",
    "        ##Output shape is 512X1X33\n",
    "        ##(Batch X Height X Width)\n",
    "        \n",
    "        \n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2)) \n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2)) \n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1))) \n",
    "        convRelu(6, True)  # 512x1x16\n",
    "\n",
    "        self.cnn = cnn\n",
    "        \n",
    "        \n",
    "        #########################Convolutional Backbone Declaration############################\n",
    "        \n",
    "        \n",
    "        \n",
    "        #########################Inherit LSTM function from LSTM function######################\n",
    "        \n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh),\n",
    "            BidirectionalLSTM(nh, nh, nclass))\n",
    "        \n",
    "        #########################Inherit LSTM function from LSTM function######################\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        #input is the input image in (Batch, Channel, Height, Width) form\n",
    "        \n",
    "        \n",
    "        #conv = Feature extracted by Convolutional Network\n",
    "        conv = self.cnn(input)\n",
    "        \n",
    "        \n",
    "        #######convert feature(conv) so LSTM can read it##################\n",
    "        \n",
    "        b, c, h, w = conv.size()\n",
    "        #print(conv.shape)\n",
    "        #make sure height is 1, we will predicting along the sequnce\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        \n",
    "        \n",
    "        conv = conv.squeeze(2) # b *512 * width\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "        \n",
    "        #############################################################\n",
    "        \n",
    "        \n",
    "        #############Send to LSTM then###############################\n",
    "        #############softmax it to get ##############################\n",
    "        #############probability between 0 and 1#####################\n",
    "        ###Softmax across dimension 2 because it will have###########\n",
    "        ####288 possible labels and they will have values############\n",
    "        ####(probability distribution)(between 0 and 1)##############\n",
    "        output = F.log_softmax(self.rnn(conv), dim=2)\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "###########weight initialization helps model achieve better###########\n",
    "#############gradients gradually, experiment with HE intialization####\n",
    "#############Xavier init etc, if possible#############################\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    " \n",
    "#def weight_init(m): \n",
    "#\tif isinstance(m, nn.Linear):\n",
    "#\t\tsize = m.weight.size()\n",
    "#\t\tfan_out = size[0] # number of rows\n",
    "#\t\tfan_in = size[1] # number of columns\n",
    "#\t\tvariance = np.sqrt(2.0/(fan_in + fan_out))\n",
    "#\t\tm.weight.data.normal_(0.0, variance)        \n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "#####Send model after intializing weight##############################        \n",
    "def get_crnn():\n",
    "    \n",
    "    #(Initial Image Height, Feature Height, Labels, LSTM hidden Layer)\n",
    "    model = CRNN(32, 1, 159, 256)\n",
    "    model.apply(weights_init)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The moment you have been waiting for,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### (IMPORTANT NOTE). Remember to change the directory of the dataset to the place the dataset is located. An example is given below in the paths locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the functions then understand the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Necessary Imports\n",
    "\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRNN(\n",
      "  (cnn): Sequential(\n",
      "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu4): ReLU(inplace=True)\n",
      "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu5): ReLU(inplace=True)\n",
      "    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu6): ReLU(inplace=True)\n",
      "  )\n",
      "  (rnn): Sequential(\n",
      "    (0): BidirectionalLSTM(\n",
      "      (rnn): LSTM(512, 256, bidirectional=True)\n",
      "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): BidirectionalLSTM(\n",
      "      (rnn): LSTM(256, 256, bidirectional=True)\n",
      "      (embedding): Linear(in_features=512, out_features=159, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "cnn.conv0.weight 576\n",
      "cnn.conv0.bias 64\n",
      "cnn.conv1.weight 73728\n",
      "cnn.conv1.bias 128\n",
      "cnn.conv2.weight 294912\n",
      "cnn.conv2.bias 256\n",
      "cnn.batchnorm2.weight 256\n",
      "cnn.batchnorm2.bias 256\n",
      "cnn.conv3.weight 589824\n",
      "cnn.conv3.bias 256\n",
      "cnn.conv4.weight 1179648\n",
      "cnn.conv4.bias 512\n",
      "cnn.batchnorm4.weight 512\n",
      "cnn.batchnorm4.bias 512\n",
      "cnn.conv5.weight 2359296\n",
      "cnn.conv5.bias 512\n",
      "cnn.conv6.weight 1048576\n",
      "cnn.conv6.bias 512\n",
      "cnn.batchnorm6.weight 512\n",
      "cnn.batchnorm6.bias 512\n",
      "rnn.0.rnn.weight_ih_l0 524288\n",
      "rnn.0.rnn.weight_hh_l0 262144\n",
      "rnn.0.rnn.bias_ih_l0 1024\n",
      "rnn.0.rnn.bias_hh_l0 1024\n",
      "rnn.0.rnn.weight_ih_l0_reverse 524288\n",
      "rnn.0.rnn.weight_hh_l0_reverse 262144\n",
      "rnn.0.rnn.bias_ih_l0_reverse 1024\n",
      "rnn.0.rnn.bias_hh_l0_reverse 1024\n",
      "rnn.0.embedding.weight 131072\n",
      "rnn.0.embedding.bias 256\n",
      "rnn.1.rnn.weight_ih_l0 262144\n",
      "rnn.1.rnn.weight_hh_l0 262144\n",
      "rnn.1.rnn.bias_ih_l0 1024\n",
      "rnn.1.rnn.bias_hh_l0 1024\n",
      "rnn.1.rnn.weight_ih_l0_reverse 262144\n",
      "rnn.1.rnn.weight_hh_l0_reverse 262144\n",
      "rnn.1.rnn.bias_ih_l0_reverse 1024\n",
      "rnn.1.rnn.bias_hh_l0_reverse 1024\n",
      "rnn.1.embedding.weight 81408\n",
      "rnn.1.embedding.bias 159\n",
      "8393887\n",
      "{'<eow>': 1, 'ম': 2, 'জ': 3, 'ি': 4, 'ব': 5, 'ু': 6, 'স': 7, 'ে': 8, 'দ্ধ': 9, 'প': 10, 'া': 11, 'ৌ': 12, 'ত': 13, 'ন্ত': 14, '্র': 15, 'ক': 16, 'ঘ': 17, 'ো': 18, 'ষ': 19, 'র': 20, 'হ': 21, 'ট': 22, 'অ': 23, 'ন': 24, 'ষ্ঠ': 25, 'ূ': 26, 'চ': 27, 'ী': 28, 'দ': 29, 'ছ': 30, 'ই': 31, 'ড': 32, 'ৃ': 33, '্য': 34, 'শ': 35, 'ৈ': 36, 'ল': 37, 'ভ': 38, 'স্ট': 39, 'ও': 40, 'ম্প': 41, 'য': 42, 'ক্ত': 43, 'ম্ম': 44, 'ক্স': 45, 'গ': 46, 'ঈ': 47, 'জ্ঞ': 48, 'ধ': 49, 'উ': 50, 'এ': 51, 'জ্জ': 52, 'ঁ': 53, 'ধ্ব': 54, 'ষ্ট': 55, 'খ': 56, 'ন্ড': 57, 'স্ত': 58, 'ঙ্গ': 59, 'ঝ': 60, 'আ': 61, 'ফ': 62, 'ৎ': 63, 'ন্দ': 64, 'জ্ব': 65, 'থ': 66, 'স্ক': 67, 'ন্ধ': 68, 'ন্স': 69, 'ল্ল': 70, 'ল্ক': 71, 'ণ': 72, 'দ্দ': 73, 'ঠ': 74, 'শ্ল': 75, 'ল্ট': 76, 'ক্ষ': 77, 'ম্ব': 78, 'ত্ব': 79, 'ত্ত': 80, 'হ্ব': 81, 'দ্ব': 82, 'শ্ব': 83, 'চ্ছ': 84, 'স্ব': 85, 'ন্থ': 86, 'ন্ন': 87, 'ষ্ণ': 88, 'ত্ম': 89, 'ব্দ': 90, 'ক্ল': 91, 'ঞ্জ': 92, 'ণ্ড': 93, 'ল্প': 94, 'ট্ট': 95, 'ঞ্চ': 96, 'ঙ': 97, 'ঋ': 98, 'ব্ব': 99, 'স্থ': 100, 'ক্ট': 101, 'ম্ভ': 102, 'ঢ': 103, 'ঊ': 104, 'ঐ': 105, 'ব্ধ': 106, 'ড্ড': 107, 'স্প': 108, 'স্ম': 109, 'ব্ল': 110, 'ন্ট': 111, 'ন্ম': 112, 'গ্ন': 113, 'ল্ম': 114, 'ত্থ': 115, 'ফ্ল': 116, 'স্ফ': 117, 'ক্ক': 118, 'শ্ন': 119, 'চ্চ': 120, 'ম্ন': 121, 'ত্ন': 122, 'ণ্ট': 123, 'দ্ভ': 124, 'ষ্ম': 125, 'ঙ্ক': 126, 'ঙ্ক্ষ': 127, 'হ্ন': 128, 'প্ল': 129, 'ষ্প': 130, 'ন্দ্ব': 131, 'ক্ষ্ম': 132, 'প্ট': 133, 'প্প': 134, 'ঙ্ঘ': 135, 'ণ্ঠ': 136, 'প্ত': 137, 'ত্ত্ব': 138, 'ল্ড': 139, 'শ্ম': 140, 'প্ন': 141, 'জ্জ্ব': 142, 'দ্ম': 143, 'ঙ্খ': 144, 'ঞ': 145, 'শ্চ': 146, 'ল্গ': 147, 'ষ্ক': 148, 'স্ন': 149, 'ন্ব': 150, 'ক্ষ্ণ': 151, 'স্ল': 152, 'গ্ল': 153, 'ঔ': 154, 'ঘ্ন': 155, 'গ্ধ': 156, 'হ্ম': 157, 'ম্ল': 158}\n",
      "158\n",
      "train indices:  106471\n",
      "validation indices:  26617\n",
      "test indices:  5681\n"
     ]
    }
   ],
   "source": [
    "#Retrieve Model and print model\n",
    "\n",
    "model = get_crnn()\n",
    "model = model.cuda()\n",
    "print(model)\n",
    "\n",
    "#########Counting Model Parameters#######################\n",
    "\n",
    "#counting parameters\n",
    "def count_parameters(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.numel())\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(count_parameters(model))\n",
    "##########################################################\n",
    "\n",
    "\n",
    "###############Continuation of training###################\n",
    "\n",
    "#Path to model, if you encounter loadshedding.\n",
    "#And want to continue training\n",
    "#model.load_state_dict(torch.load('path/to/model.pth'))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "\n",
    "#########################Loss function decalaration############################\n",
    "\n",
    "\n",
    "#Zero inifinity problem, gradient collapses to zero, when 287 labels\n",
    "criterion = torch.nn.CTCLoss(blank =0, reduction='mean', zero_infinity = True)\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "#################Extract and Preprocess dataset################################\n",
    "\n",
    "##Example::\n",
    "ocr_dataset = OCRDataset('C:/Users/monsur/Desktop/BengaliAiHandwrittenDataset/TrainingTesting/testingcon')\n",
    "testocr_dataset = OCRDataset('C:/Users/monsur/Desktop/LearningPytorch/handwritingocrproject/testing/Testing')\n",
    "##ocr_dataset = OCRDataset('Path/to/dataset/out')\n",
    "\n",
    "\n",
    "##Example::\n",
    "grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i = preprocess_data('C:/Users/monsur/Desktop/BengaliAiHandwrittenDataset/TrainingTesting/testingcon')\n",
    "#grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i = preprocess_data('C:/Users/monsur/Desktop/LearningPytorch/handwritingocrproject/testing/Testing')\n",
    "##grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i = preprocess_data('Path/to/dataset/out')\n",
    "\n",
    "print(grapheme_dict_i)\n",
    "print(len(grapheme_dict_i))\n",
    "#sanity check\n",
    "#print(words_i)\n",
    "#print(labels_i)\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################Setting validation and train split########################\n",
    "\n",
    "\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "#seeding for reproducability\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Creating data indices for training and validation splits\n",
    "dataset_size = len(ocr_dataset)\n",
    "testdataset_size = len(testocr_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "testindices = list(range(testdataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "print(\"train indices: \", len(train_indices))\n",
    "test_indices = testindices\n",
    "print(\"validation indices: \", len(val_indices))\n",
    "print(\"test indices: \", len(test_indices))\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "\n",
    "#Batch Size variable (Decrease it if you hit memory error, or increase it for faster train)\n",
    "train_batch_s = 64\n",
    "valid_batch_s = 64\n",
    "test_batch_s = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= train_batch_s, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= valid_batch_s,\n",
    "                                                sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(testocr_dataset, batch_size= test_batch_s,\n",
    "                                                sampler=test_sampler)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Train and validate already########\n",
    "\n",
    "#####There's necessary stuff###########\n",
    "#####That will get printed#############\n",
    "####every epoch. Feel free to add more#\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(metrics1, metrics2):\n",
    "    \n",
    "    ###Set epoch number here\n",
    "    epoch_number = 10\n",
    "    for epoch in range(epoch_number):\n",
    "        print(\"***Epoch: {}***\".format(epoch))\n",
    "        batch_loss = 0\n",
    "        #change this for epoch\n",
    "        if epoch>(epoch_number/3):\n",
    "            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr= 0.00006)\n",
    "        if epoch>(epoch_number/5):\n",
    "            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0003)\n",
    "        else:\n",
    "            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "        for i, (inp, img_names, idx) in enumerate(tqdm(train_loader)):\n",
    "            inp = inp.cuda()\n",
    "            batch_size = inp.size(0)\n",
    "            idxs = idx.detach().numpy()\n",
    "            img_names = list(img_names)\n",
    "            words, labels, labels_size, inv_grapheme_dict = get_padded_labels(idxs, grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i)\n",
    "            preds = model(inp)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "            labels.cuda()\n",
    "            labels_size = torch.tensor(labels_size, dtype=torch.long)\n",
    "            labels_size.cuda()\n",
    "            preds_size = torch.tensor([preds.size(0)] * batch_size, dtype=torch.long)\n",
    "            preds_size.cuda()\n",
    "            loss = criterion(preds, labels, preds_size, labels_size)\n",
    "            #print(loss.item())\n",
    "            batch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = batch_loss/train_batch_s\n",
    "        print(\"Epoch Training loss: \", train_loss) #batch_size denominator 32\n",
    "        \n",
    "\n",
    "        print(\"\\n\")\n",
    "        validate(epoch, metrics1, metrics2, train_loss)\n",
    "        #if epoch%1 == 0:\n",
    "        torch.save(model.state_dict(), 'epoch{}.pth'.format(epoch))\n",
    "\n",
    "\n",
    "def validate(epoch, metrics1, metrics2, train_loss):\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        pred_ = []\n",
    "        label_ = []\n",
    "\n",
    "        total_wer = 0\n",
    "\n",
    "        print(\"***Epoch: {}***\".format(epoch))\n",
    "        batch_loss = 0\n",
    "        for i, (inp, img_names, idx) in enumerate(tqdm(validation_loader)):\n",
    "            inp = inp.cuda()\n",
    "            batch_size = inp.size(0)\n",
    "            idxs = idx.detach().numpy()\n",
    "            img_names = list(img_names)\n",
    "            words, labels, labels_size, inv_grapheme_dict = get_padded_labels(idxs, grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i)\n",
    "            preds = model(inp)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "            labels.cuda()\n",
    "            labels_size = torch.tensor(labels_size, dtype=torch.long)\n",
    "            labels_size.cuda()\n",
    "            preds_size = torch.tensor([preds.size(0)] * batch_size, dtype=torch.long) \n",
    "            preds_size.cuda()\n",
    "\n",
    "            #validation loss\n",
    "            loss = criterion(preds, labels, preds_size, labels_size)\n",
    "            #print(loss)\n",
    "            batch_loss += loss.item()\n",
    "            #print(loss.item())\n",
    "\n",
    "            _, preds = preds.max(2)\n",
    "            preds = preds.transpose(1, 0).contiguous().detach().cpu().numpy()\n",
    "            labels = labels.detach().numpy()\n",
    "            \n",
    "            for i in range(len(preds)):\n",
    "                decoded, _ = decode_prediction(preds[i], inv_grapheme_dict)\n",
    "                for x,y in zip(decoded, labels[i]):\n",
    "                    y_pred.append(x)\n",
    "                    y_true.append(y)\n",
    "                _, decoded_pred_ = decode_prediction(preds[i], inv_grapheme_dict)\n",
    "                #print(inv_grapheme_dict)\n",
    "                _, decoded_label_ = decode_prediction(labels[i], inv_grapheme_dict)\n",
    "                #print(decoded_label_)\n",
    "                \n",
    "                pred_.append(decoded_pred_)\n",
    "                label_.append(decoded_label_)\n",
    "\n",
    "        valid_loss = batch_loss/valid_batch_s\n",
    "        print(\"Epoch Validation loss: \", valid_loss) #batch_size denominator 32\n",
    "        print(\"\\n\")\n",
    "        #print(pred_)\n",
    "        #print(label_)\n",
    "        total_wer = compute_wer(pred_, label_)\n",
    "        print(\"Total_Word_Error_Rate: %.4f\" % total_wer)\n",
    "\n",
    "        #change in number of labels\n",
    "        \n",
    "        report = classification_report(y_true, y_pred, labels = np.arange(1,288), zero_division=0)\n",
    "        f1_micro = f1_score(y_true, y_pred, average = 'micro', zero_division=0)\n",
    "        f1_macro = f1_score(y_true, y_pred, average = 'macro', zero_division=0)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "\n",
    "        #Absolute word matching\n",
    "        abs_correct = absolute_word_match(pred_, label_)\n",
    "        \n",
    "        ###this has been made change by monsur\n",
    "\n",
    "\n",
    "\n",
    "        with open('Results__Report_epoch{}.txt'.format(epoch), 'w') as fout2:\n",
    "            fout2.write(report)\n",
    "\n",
    "\n",
    "        with open('results.txt','w', encoding = 'utf-8') as fout:\n",
    "            for x,y in zip(pred_, label_):\n",
    "                fout.write(\"True: {}\".format(y))\n",
    "                fout.write(\"\\n\")\n",
    "                fout.write(\"Pred: {}\".format(x))\n",
    "                fout.write(\"\\n\\n\")\n",
    "        print(\"Accuracy: %.4f\" % accuracy)\n",
    "        print(\"F1 Micro Score: %.4f\" % f1_micro)\n",
    "        print(\"F1 Macro Score: %.4f\" % f1_macro)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        ################################################JSON Dumps\n",
    "        metrics1['epoch'].append(epoch)\n",
    "        metrics1['accuracy'].append(accuracy)\n",
    "        metrics1['train_loss'].append(train_loss)\n",
    "        metrics1['valid_loss'].append(valid_loss)\n",
    "        metrics1['total_wer'].append(total_wer)\n",
    "        metrics1['f1_micro'].append(f1_micro)\n",
    "        metrics1['f1_macro'].append(f1_macro)\n",
    "        metrics1['absolute_word_correct'].append(abs_correct)\n",
    "\n",
    "        json.dump( metrics1, open( \"metrics(general).json\", 'w' ))\n",
    "\n",
    "        metrics2['epoch'].append(epoch)\n",
    "        metrics2['report'].append(report)\n",
    "\n",
    "        json.dump( metrics2, open( \"metrics(report).json\", 'w' ))\n",
    "\n",
    "\n",
    "        print(\"End of Epoch {}\".format(epoch))\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(metrics1, metrics2):\n",
    "    epoch_number = 1\n",
    "    for epoch in range(epoch_number):\n",
    "        with torch.no_grad():\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            pred_ = []\n",
    "            label_ = []\n",
    "\n",
    "            total_wer = 0\n",
    "            model.load_state_dict(torch.load('epoch2.pth'))\n",
    "            model.eval()\n",
    "            print(\"***Epoch: {}***\".format(epoch))\n",
    "            batch_loss = 0\n",
    "            for i, (inp, img_names, idx) in enumerate(tqdm(test_loader)):\n",
    "                inp = inp.cuda()\n",
    "                batch_size = inp.size(0)\n",
    "                idxs = idx.detach().numpy()\n",
    "                img_names = list(img_names)\n",
    "                words, labels, labels_size, inv_grapheme_dict = get_padded_labels(idxs, grapheme_dict_i, inv_grapheme_dict_i, words_i, labels_i, lengths_i)\n",
    "                preds = model(inp)\n",
    "                #print(preds)\n",
    "                labels = torch.tensor(labels, dtype=torch.long)\n",
    "                labels.cuda()\n",
    "                #print(\"Labels\",labels)\n",
    "                labels_size = torch.tensor(labels_size, dtype=torch.long)\n",
    "                labels_size.cuda()\n",
    "                preds_size = torch.tensor([preds.size(0)] * batch_size, dtype=torch.long) \n",
    "                preds_size.cuda()\n",
    "\n",
    "                #validation loss\n",
    "                loss = criterion(preds, labels, preds_size, labels_size)\n",
    "                #print(loss)\n",
    "                batch_loss += loss.item()\n",
    "                #print(loss.item())\n",
    "\n",
    "                _, preds = preds.max(2)\n",
    "                preds = preds.transpose(1, 0).contiguous().detach().cpu().numpy()\n",
    "                labels = labels.detach().numpy()\n",
    "            \n",
    "                for i in range(len(preds)):\n",
    "                    decoded, _ = decode_prediction(preds[i], inv_grapheme_dict)\n",
    "                    for x,y in zip(decoded, labels[i]):\n",
    "                        y_pred.append(x)\n",
    "                        y_true.append(y)\n",
    "                    _, decoded_pred_ = decode_prediction(preds[i], inv_grapheme_dict)\n",
    "                    #print(inv_grapheme_dict)\n",
    "                    _, decoded_label_ = decode_prediction(labels[i], inv_grapheme_dict)\n",
    "                    #print(decoded_label_)\n",
    "                \n",
    "                    pred_.append(decoded_pred_)\n",
    "                    label_.append(decoded_label_)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            print(inv_grapheme_dict)\n",
    "\n",
    "            test_loss = batch_loss/test_batch_s\n",
    "            print(\"Epoch Test loss: \",test_loss) #batch_size denominator 32\n",
    "            print(\"\\n\")\n",
    "            #print(pred_)\n",
    "            #print(label_)\n",
    "            total_wer = compute_wer(pred_, label_)\n",
    "            print(\"Total_Word_Error_Rate: %.4f\" % total_wer)\n",
    "            \n",
    "            abs_correct = absolute_word_match(pred_, label_)\n",
    "            \n",
    "            test_accuracy = accuracy_score(y_true, y_pred)\n",
    "            print(\"test Accuracy: %.4f\" % test_accuracy)\n",
    "            with open('testresults.txt','w', encoding = 'utf-8') as fout:\n",
    "                for x,y in zip(pred_, label_):\n",
    "                    fout.write(\"True: {}\".format(y))\n",
    "                    fout.write(\"\\n\")\n",
    "                    fout.write(\"Pred: {}\".format(x))\n",
    "                    fout.write(\"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###UP UP AND AWAAAAYYYYYY#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Epoch: 0***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [00:27<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '<eow>', 2: 'ম', 3: 'জ', 4: 'ি', 5: 'ব', 6: 'ু', 7: 'স', 8: 'ে', 9: 'দ্ধ', 10: 'প', 11: 'া', 12: 'ৌ', 13: 'ত', 14: 'ন্ত', 15: '্র', 16: 'ক', 17: 'ঘ', 18: 'ো', 19: 'ষ', 20: 'র', 21: 'হ', 22: 'ট', 23: 'অ', 24: 'ন', 25: 'ষ্ঠ', 26: 'ূ', 27: 'চ', 28: 'ী', 29: 'দ', 30: 'ছ', 31: 'ই', 32: 'ড', 33: 'ৃ', 34: '্য', 35: 'শ', 36: 'ৈ', 37: 'ল', 38: 'ভ', 39: 'স্ট', 40: 'ও', 41: 'ম্প', 42: 'য', 43: 'ক্ত', 44: 'ম্ম', 45: 'ক্স', 46: 'গ', 47: 'ঈ', 48: 'জ্ঞ', 49: 'ধ', 50: 'উ', 51: 'এ', 52: 'জ্জ', 53: 'ঁ', 54: 'ধ্ব', 55: 'ষ্ট', 56: 'খ', 57: 'ন্ড', 58: 'স্ত', 59: 'ঙ্গ', 60: 'ঝ', 61: 'আ', 62: 'ফ', 63: 'ৎ', 64: 'ন্দ', 65: 'জ্ব', 66: 'থ', 67: 'স্ক', 68: 'ন্ধ', 69: 'ন্স', 70: 'ল্ল', 71: 'ল্ক', 72: 'ণ', 73: 'দ্দ', 74: 'ঠ', 75: 'শ্ল', 76: 'ল্ট', 77: 'ক্ষ', 78: 'ম্ব', 79: 'ত্ব', 80: 'ত্ত', 81: 'হ্ব', 82: 'দ্ব', 83: 'শ্ব', 84: 'চ্ছ', 85: 'স্ব', 86: 'ন্থ', 87: 'ন্ন', 88: 'ষ্ণ', 89: 'ত্ম', 90: 'ব্দ', 91: 'ক্ল', 92: 'ঞ্জ', 93: 'ণ্ড', 94: 'ল্প', 95: 'ট্ট', 96: 'ঞ্চ', 97: 'ঙ', 98: 'ঋ', 99: 'ব্ব', 100: 'স্থ', 101: 'ক্ট', 102: 'ম্ভ', 103: 'ঢ', 104: 'ঊ', 105: 'ঐ', 106: 'ব্ধ', 107: 'ড্ড', 108: 'স্প', 109: 'স্ম', 110: 'ব্ল', 111: 'ন্ট', 112: 'ন্ম', 113: 'গ্ন', 114: 'ল্ম', 115: 'ত্থ', 116: 'ফ্ল', 117: 'স্ফ', 118: 'ক্ক', 119: 'শ্ন', 120: 'চ্চ', 121: 'ম্ন', 122: 'ত্ন', 123: 'ণ্ট', 124: 'দ্ভ', 125: 'ষ্ম', 126: 'ঙ্ক', 127: 'ঙ্ক্ষ', 128: 'হ্ন', 129: 'প্ল', 130: 'ষ্প', 131: 'ন্দ্ব', 132: 'ক্ষ্ম', 133: 'প্ট', 134: 'প্প', 135: 'ঙ্ঘ', 136: 'ণ্ঠ', 137: 'প্ত', 138: 'ত্ত্ব', 139: 'ল্ড', 140: 'শ্ম', 141: 'প্ন', 142: 'জ্জ্ব', 143: 'দ্ম', 144: 'ঙ্খ', 145: 'ঞ', 146: 'শ্চ', 147: 'ল্গ', 148: 'ষ্ক', 149: 'স্ন', 150: 'ন্ব', 151: 'ক্ষ্ণ', 152: 'স্ল', 153: 'গ্ল', 154: 'ঔ', 155: 'ঘ্ন', 156: 'গ্ধ', 157: 'হ্ম', 158: 'ম্ল'}\n",
      "Epoch Test loss:  17.979314386844635\n",
      "\n",
      "\n",
      "Total_Word_Error_Rate: 7.1727\n",
      "Absolute word match count is 0\n",
      "test Accuracy: 0.0201\n"
     ]
    }
   ],
   "source": [
    "metrics1 = {\n",
    "'epoch': [],\n",
    "'accuracy': [],\n",
    "'train_loss': [],\n",
    "'valid_loss': [],\n",
    "'total_wer': [],\n",
    "'f1_micro': [],\n",
    "'f1_macro': [],\n",
    "'absolute_word_correct': [],\n",
    "}\n",
    "\n",
    "metrics2 = {\n",
    "'epoch': [],\n",
    "'report': [],\n",
    "}\n",
    "\n",
    "#train(metrics1, metrics2)\n",
    "test(metrics1,metrics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu4): ReLU(inplace=True)\n",
       "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu5): ReLU(inplace=True)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu6): ReLU(inplace=True)\n",
       "  )\n",
       "  (rnn): Sequential(\n",
       "    (0): BidirectionalLSTM(\n",
       "      (rnn): LSTM(512, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (1): BidirectionalLSTM(\n",
       "      (rnn): LSTM(256, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=159, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################################################################################\n",
    "########Things you can try out################################################################################\n",
    "##########1) Try attention modules in place of sequential models like RNN and LSTM#####################################\n",
    "########2) Find augmentation schemes that help the generalization capability of the model#################################\n",
    "########3) Try out different convolutional backbone architectures (HRnet, ResNext, OSA etc) in the model####################\n",
    "########4) Try different stuff in the LSTM module to understand it's weaknesses and how to overcome them###################\n",
    "####### AND if you are up for the challenge A better loss function than CTC#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
